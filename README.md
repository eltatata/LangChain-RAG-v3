# Conversational RAG with LangChain v3

This project implements a Conversational RAG (Retrieval-Augmented Generation) using the new features introduced in LangChain v3, including an improved memory system, multi-thread conversation handling, and LangGraph for orchestration.

The service is built with Bun, TypeScript, Express (MVC), and MongoDB (Vector Store).

## ğŸš€ Main Technologies

- **Bun** â€“ Modern and fast JavaScript runtime.
- **TypeScript** â€“ Static typing for scalability and maintainability.
- **Express** â€“ Web framework with an MVC architecture.
- **LangChain** â€“ Framework for RAG, memory, and conversational flows.
- **LangGraph** â€“ Conversation flow orchestration.
- **Enhanced Memory** â€“ Support for multiple conversation threads.
- **MongoDB** (Vector Store) â€“ Semantic search and embedding storage.
- **PDF Loader** â€“ Context ingestion from PDF documents.

## ğŸ“Œ Key Features

- âœ… Full Conversational RAG implementation.
- âœ… Context ingestion from PDF files.
- âœ… MongoDB Vector Store for embeddings.
- âœ… Conversation threads managed via client request headers.
- âœ… Middleware that validates and manages thread-related information.
- âœ… Decoupled logic in the services layer, including:
  - RAG configuration with LangChain.
  - LangGraph integration.
  - Prompt template definitions.
  - Conversation memory management.

## ğŸ“‚ Project Structure
```
â””â”€â”€ ğŸ“src
    â””â”€â”€ ğŸ“config
        â””â”€â”€ ğŸ“envs
            â”œâ”€â”€ envs.ts
        â””â”€â”€ ğŸ“errors
            â”œâ”€â”€ customer-errors.ts
            â”œâ”€â”€ error-handler.ts
        â”œâ”€â”€ index.ts
    â””â”€â”€ ğŸ“controllers
        â”œâ”€â”€ index.ts
        â”œâ”€â”€ rag.controller.ts
    â””â”€â”€ ğŸ“database
        â”œâ”€â”€ database.connection.ts
    â””â”€â”€ ğŸ“docs
        â”œâ”€â”€ estruc-datos.pdf
    â””â”€â”€ ğŸ“interfaces
        â””â”€â”€ ğŸ“shared
            â”œâ”€â”€ shared.interfaces.ts
        â”œâ”€â”€ index.ts
    â””â”€â”€ ğŸ“middlewares
        â”œâ”€â”€ index.ts
        â”œâ”€â”€ session-validation.middleware.ts
    â””â”€â”€ ğŸ“routes
        â”œâ”€â”€ index.ts
        â”œâ”€â”€ rag.routes.ts
    â””â”€â”€ ğŸ“scripts
        â”œâ”€â”€ ingest-data.ts
    â””â”€â”€ ğŸ“server
        â”œâ”€â”€ index.ts
        â”œâ”€â”€ router.ts
        â”œâ”€â”€ server.ts
    â””â”€â”€ ğŸ“services
        â”œâ”€â”€ index.ts
        â”œâ”€â”€ rag.service.ts
    â””â”€â”€ ğŸ“utils
        â”œâ”€â”€ prompt-teplate.ts
    â””â”€â”€ app.ts
```

## âš¡Workflow

1. Data Ingestion
    - The system loads a PDF, processes it, and generates embeddings stored in MongoDB.
2. Conversational Flow with RAG
    - The client sends messages through the API.
    - Headers include the conversation thread identifier.
    - Middleware validates the thread and passes it to the services layer.
3. Processing with LangChain + LangGraph
    - Executes RAG logic (retrieval + generation).
    - Keeps thread-specific memory to handle independent conversations.

## ğŸ¥ Demo

## ğŸ› ï¸ Installation & Usage
1. Clone repository
```
git clone https://github.com/eltatata/LangChain-RAG-v3.git
```
2. Install dependencies
```
bun install
```
3. Configure environment variables
```
cp .env.example .env
```
4. Run in development mode
```
bun dev
```

## ğŸ”‘ Environment Variables

The .env file must include values such as:

```
PORT=3000

DATABASE_NAME=langchain-v3-rag
COLLECTION_NAME=data
MONGODB_ATLAS_URI=your_mongodb_atlas_uri_here

OPENAI_API_KEY=your_openai_api_key_here
```

## ğŸ¤ Contributing

Contributions are welcome!
Fork the repository, create a feature branch, and submit a PR ğŸš€.
